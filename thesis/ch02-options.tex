
\chapter{云计算资源管理与调度相关技术}
\label{chap:outline}

对于企业和公司，为了完成各种对外的服务以及公司内部业务逻辑，需要大量的硬件资源, 而硬件的资源的代价往往比较昂
贵，所以如何充分挖掘硬件资源潜力从而增加硬件的利用率

\section{OpenStack云计算平台}

OpenStack是一个美国国家航空航天局和Rackspace合作研发的，以Apache许可证授权，并且是一个自由软件和开放源代码
项目。

OpenStack是一个云平台管理的项目，它不是一个软件。这个项目由几个主要的组件组合起来完成一些具体的工作。

OpenStack是一个旨在为公共及私有云的建设与管理提供软件的开源项目。它的社区拥有超过130家企业及1350位开发者，这
些机构与个人都将OpenStack作为基础设施即服务（简称IaaS）资源的通用前端。OpenStack项目的首要任务是简化云的部
署过程并为其带来良好的可扩展性。OpenStack的核心组件有以下9个：
\begin{itemize}
\item 计算(Compute):Nova，Nova是OpenStack云中的计算组织控制器。支持OpenStack云中实例（instances）生
命周期的所有活动都由Nova处理。其中的调度器nova-schedule作为一个守护进程运行，通过恰当的调度算法从可用资源池
获得一个计算服务。nova-scheduler会根据诸如负载、内存、可用域的物理距离、CPU构架等作出调度决定。
\item 对象存储(Object):Swift，其最初是由Rackspace公司开发的高可用分布式对象存储服务，并于2010年贡献
给OpenStack开源社区作为其最初的核心子项目之一，为其Nova子项目提供虚机镜像存储服务。Swift 支持多租户模式、
容器和对象读写操作，适合解决互联网的应用场景下非结构化数据存储问题。
\item 镜像(Image):Glance,用来管理在 OpenStack 集群中的镜像，但不负责实际的存储。它为从简单文件系统到对
象存储系统(如OpenStack-Swift项目)的多种存储技术提供了一个抽象。除了实际的磁盘镜像之外，它还保存描述镜像的元数据和状态信息。
\item 身份(Identity):Keystone(OpenStack Identity Service)是OpenStack框架中，负责身份验证、服务规则和服务令牌的功能， 它实现了OpenStack的Identity API。
\item 网络地址管理(Network):Neutron是OpenStack核心项目之一，提供云计算环境下的虚拟网络功能.
\item 块存储(Block):Cinder,Cinder用来提供块存储(Block Storage)，类似于Amazon的EBS块存储服务，OpenStack中的实例是不能持久化的，需要挂载volume，在volume中实现持久化。Cinder就是提供对 volume 实际需要的存储块单元的实现管理功能。
\item UI管理界面(Dashboard):Horizon,Horizon套件提供IT人员一个图形化的网页接口，让IT人员可以综观云端服务目前的规模与状态，并且，能够统一存取、部署与管理所有云端服务所使用到的资源。
\item 测量(Metering):Ceilometer,主要负责监控数据的采集，采集的项目包括虚拟机的性能数据，n
eutron-l3-router使用的网络带宽，glance，cinder，swift等租户使用信息，
甚至是通过snmp采集物理机的信息，以及采集支持opendaylight的网络设备信息。
\item 编配(Orchestration):Heat 类似于AWS的CloudFormation, heat实现了一种自动化的通过简单定义和配置就能实现的云部署方式。
可以在heat模板中定义连串相关任务，然后交由heat，由heat按照一定的顺序执行heat模板中定义的一连串任务。利用heat还可以连接到neutron来帮助编排负载均衡和其他网络功能。
\end{itemize}
\section{资源管理抽象模型}
 
资源管理调度模型如图所示

图中说明了一个资源管理与系统的抽象模型。从概念上讲资源管理与调度系统的主要目的是根据用户任务的请求，
从集群中分配资源。目前资源分配的主要资源主要包括内存,CPU,网络和IO资源等.而资源调度的模型主要涉及3个要素
资源组织模型,调度算法和任务组织方式。
\begin{enumerate}
\item 资源组织模型主要是整理和规整集群中所有的资源，以方便后续的资源分配过程。通常的做法是将资源组织成为多层级队列的形式，
例如Corona的"All-resource->group->pool"的三级队列模式组织，另外平级队列或是单队列也是常见的资源
组织模型，其本质是多层级队列的特殊形式。
\item 资源调度算法的负责将集群中的资源按照一定的策略分配的任务。常见的调度策略有FIFO调度算法、公平调度算法、能力调度算法以及延迟调度算法等。具体策略可以参加本章2.4资源调度算法。
\item 任务组织方式主要是将多用户提交的任务通过一定的方式组织起来，来方便调度算法进行分配。常见的组织方式是将任务以队列的形式组织起来，例如Hadoop1.0中将任务按照多队列组织，队列之间采用平级关系，而在hadoop2.0中的任务队列则增加了层级队列的树形结构，用以提供更加灵活的方式来管理任务队列。
\end{enumerate}
\section{资源管理与调度系统范型}
目前有多种多种的资源管理和调度系统实现，根据实际的宏观运行机制进行分类，可以分为以下几种资源管理与调度系统范型:集中式调度，两级调度器和状态共享调度器。

\subsection{集中式调度器}
集中式调度器在整个系统中只有一个唯一的全局调度器，其特点是，资源的调度和作业的管理功能全部放到一个进程中完成，在
集群上运行的所有框架或者是计算任务的资源请求均由集中式调度器来满足，因此，整个调度系统在集群上缺乏并发性，并且所有
的调度逻辑均由集中式调度器独自完成。开源界典型的代表是Hadoop JobTracker的实现。

这类调度器又分为2种类型，一种是单路径调度器,另一种是多路径调度器。
\begin{enumerate}
\item 单路径调度器(Single Path Scheduler):这种调度器是指不管任务的类型均采用全局统一的调度器进行资源管理，
这种调度算法基本是采用融合考虑各种因素来实现的调度器,在此基础之上结合任务的优先级，集群资源的状态统计，决定调度的
任务资源分配和调度顺序。
\item 多路径调度器(Multi Path scheduler):这种调度器在单路经调度器的基础之上做了该进,首先支持多种调度策略,其大致思路
是将调度算法模块化,根据任务的类型进行调度,比如批处理的任务采用批处理的调度算法,计算量大的任务采用计算量大的调度
算法,在具体的实现的时候各个算法独自实现,而在调度器的逻辑中根据任务类型进行选择,其选择类型类似于程序语言的Switch
-Case分支路径,这种调度器可以根据调度算法的类型采用多线程的方式进行实现,较单路经调度器的调度灵活性和
并发性有了一定的提高
\end{enumerate}

但是集中式调度器的设计方式的缺点也是比较明显的。
\begin{enumerate}
\item 由于将所有的调度逻辑均写入中央调度器中，所以实现的逻辑比较负载，可扩展较差。这点在单路径调度器上尤其明显，多
路径调度器虽然在此基础之上进行了改进，但是在针对某个类型任务的算法进行替换的过程中，中央调度器此时不得不整体停止，
对其他的调度任务产生影响。
\item 集群的规模受限，中央调度器的并发性不足.由于是对整个系统的全局资源进行调度，在小规模集群上可以完成其调度工
作而当集群规模扩大时，任务和工作负载加大，当调度与资源分配决策执行时间较长的情况下，这个时候往往调度器会首先达到
工作饱和，此时，后续任务会花费大量的时间在等待被调度，从而导致集中式调度器成为整个系统的运行瓶颈，严重影响系统的运
行性能。
\end{enumerate}

\subsection{两层调度器}
为了解决中央式调度器的不足，双层调度器是一种很容易想到的解决之。两层调度器将整个系统的调度工作分成两个级别：
中央调度器和框架调度器。中央调度器负责集群系统中所有资源的管理，并按照一定的策略将集群中所有的资源分配给各个计算
框架，从总体上看，中央调度器是一种比较粗粒度的资源调度，各个计算框架在接受到资源的分配后，根据自身计算任务的需要
再次按照框架调度器调度进行任务执行的调度。在这种情况下，中央调度器进行资源的切分，而框架调度器重点则在任务的调度
上，框架调度器进一步细粒度的使用中央调度器所划分的资源，本质上是分而治之策略或者是策略下放机制。Mesos，YARN是
典型的两层调度的实现。

在Mesos中资源管理部分由两部分组成：分别是Mesos Master和Mesos Slave，其中，Mesos Slave是每个节点上的代理，
负责向Master汇报信息和接收并执行来自Master的命令，而Master则是一个轻量级中央化的资源管理器，负责管理和
分配整个集群中的资源。如果一个应用程序想通过Mesos资源管理系统申请和使用资源，需编写两个组件：框架调度
器和框架执行器，其中，框架调度器负责从Mesos Master上获取资源、将资源分配给自己内部的各个应用程序，并控
制应用程序的执行过程；而框架执行器运行在Mesos Slave中，负责运行该框架中的任务。当前很多框架可以接入Mesos中
，包括Hadoop、MPI、Spark等。

Mesos Master仅将可用的资源推送给各个框架，而框架自己选择使用还是拒绝这些资源；
一旦框架（比如Hadoop JobTracker）接收到新资源后，再进一步将资源分配给其内部的各个应用程
序（各个MapReduce作业），进而实现双层调度。

与集中式调度器相比，双层调度器由于存在框架调度器，各个框架调度器仅仅与中央调度器进行耦合，所以具有良好的并发性，系
统的整体性能较佳，也比较适合大规模的多任务高负载的计算任务，
各个框架调度器并不知道整个集群资源使用情况，只是被动的接收资源；
双层调度器的缺点是：
1）  各个框架无法知道整个集群的实时资源使用情况。
很多框架不需要知道整个集群的实时资源使用情况就可以运行的很顺畅，但是对于其他一些应用，为之提供实时资源使
用情况可以为之提供潜在的优化空间，比如，当集群非常繁忙时，一个服务失败了，是选择换一个节点重新运行它呢，
还是继续在这个节点上运行？通常而言，换一个节点可能会更有利，但是，如果此时集群非常繁忙，所有节点只剩下小
于5GB的内存，而这个服务需要10GB内存，那么换一个节点可能意味着长时间等待资源释放，而这个等待时间是无法
确定的。
2）  采用悲观锁，并发粒度小。
在数据库领域，悲观锁与乐观锁争论一直不休，悲观锁通常采用锁机制控制并发，这会大大降低性能，而乐观锁则采用
多版本并发控制(MVCC ,Multi-Version Concurrency Control)，典型代表是MySQL innoDB，这种机制通过多版本方式控
制并发，可大大提升性能。在Mesos中，在任意一个时刻，Mesos资源调度器只会将所有资源推送给任意一个框架，等
到该框架返回资源使用情况后，才能够将资源推动给其他框架，因此，Mesos资源调度器中实际上有一个全局锁，这大
大限制了系统并发性。
\subsection{状态共享调度器}
为了克服双层调度器的以上两个缺点，Google开发了下一代资源管理系统Omega，Omega是一种基于共享状态的调度
器，该调度器将双层调度器中的集中式资源调度模块简化成了一些持久化的共享数据（状态）和针对这些数据的验证代
码，而这里的“共享数据”实际上就是整个集群的实时资源使用信息。一旦引入共享数据后，共享数据的并发访问方式就
成为该系统设计的核心，而Omega则采用了传统数据库中基于多版本的并发访问控制方式
（也称为“乐观锁”, MVCC, Multi-Version Concurrency Control），这大大提升了Omega的并发性。

由于Omega不再有集中式的调度模块，因此，不能像Mesos或者YARN那样，在一个统一模块中完成以下功能：对整个
集群中的所有资源分组，限制每类应用程序的资源使用量，限制每个用户的资源使用量等，这些全部由各个应用程序
调度器自我管理和控制，根据论文所述，Omega只是将优先级这一限制放到了共享数据的验证代码中，即当同时由多
个应用程序申请同一份资源时，优先级最高的那个应用程序将获得该资源，其他资源限制全部下放到各个子调度器。
引入多版本并发控制后，限制该机制性能的一个因素是资源访问冲突的次数，冲突次数越多，系统性能下降的越快，
而google通过实际负载测试证明，这种方式的冲突次数是完全可以接受的。
Omega论文中谈到，Omega是从Google现有系统上演化而来的。既然这篇论文只介绍了Omega的调度器架构，我们
可推测它的整体架构类似于Mesos，这样，如果你了解Mesos，那么可知道，我们可以通过仅修改Mesos的Master将
之改造成一个Omega。

\section{资源调度算法}

对于企业和公司，为了完成各种对外的服务以及公司内部业务逻辑，需要大量

\subsection{FIFO调度算法}
对于企业和公司，为了完成各种对外的服务以及公司内部业务逻辑，需要大量
\subsection{公平调度策略}
对于企业和公司，为了完成各种对外的服务以及公司内部业务逻辑，需要大量
\subsection{能力调度器}
对于企业和公司，为了完成各种对外的服务以及公司内部业务逻辑，需要大量
\subsection{延迟调度策略}
对于企业和公司，为了完成各种对外的服务以及公司内部业务逻辑，需要大量

\section{本章小结}

对于企业和公司，为了完成各种对外的服务以及公司内部业务逻辑，需要大量
