\chapter{CBDRF调度系统的设计与实现}
\label{cha:frontmatter}
本节针对关联性任务存在的资源利用不足，性能不佳的问题，在基于图论和公平性的理论上，首先设计了CBDRF调度系统
的调度算法，接下来给出了CBDRF调度系统核心模块的设计，并在此基础上给出了CBDRF调度系统的实现的一种方式。

\section{CBDRF算法设计}
CBDRF调度系统的核心是其调度算法，本节首先介绍了CBDRF算法的调度流程，接下来分别介绍其中的各个核心
调度模块，并给出调度逻辑的伪代码和流程图。
\subsection{CBDRF调度的流程}
CBDRF调度算法从解析用户请求开始，到最终的输出调度结果，主要经过一下10个步骤：
\begin{enumerate}
\item 首先，资源解析器解析用户请求，为每个请求初始化request实例。
\item 由关联任务的解析进行解析，生成带有特殊标记的任务序列。
\item request实例向资源调度迭代器发送解析数据，同时资源调度迭代器向资源管理控制器发送请求，以获取云计算平台的的实时资源状态。
\item 资源管理控制器为每个物理机创建host实例。
\item 将用户的请求作为要分配的资源池，当多个资源请求到来的时候将这些资源请求抽象为分配给物理机的总资源，
同时将物理机的容量作为实际的请求向量计算每个host(物理机)的dominantShare，
为资源向量所拥有的资源的占有率中的最大值称物理机户的dominantShare.
同时计算dominantDesire为资源向量上剩余最多的资源。
\item 由资源调度迭代排序器和资源调度迭代器运行基于DRF算法的分配，进行迭代的调度分配资源算法。
\item 资源调度迭代评估器利用Jain’s fairness index:简氏公平指数，计算资源请求request的dominantShare向量
$TS\left({ts}_{1},{ts}_{2},…{ts}_{k}\right )$，云计算平台物理机向量dominantShare向量$HS\left({hs}_{1},{hs}_{2},…{hs}_{n}\right )$，记录此时的$Value = \frac{J(TS)}{J(HS)}$和分配方案。
\item 资源调度迭代评估器计算$Value = \frac{J(TS)}{J(HS)}$，如果大于之前的最优值，记录此式的解决方案。
\item 资源调度迭代合并器从已经任务解析的任务序列中，按照关联任务的，从而更新合并mergeHistory跳至步骤6，否则跳至步骤10。
\item 算法结束，输出解决方案。
\end{enumerate}
\subsection{关联任务的解析}
关联任务的解析，是算法的预处理环节中关键的一步。这一步需要将对关联的任务的关联关系进行解析。
对于不同类型的任务，对资源的需求是不同的。需要对不同关联类型的任务进行不同的关联任务解析。
对于无关联的任务，不需要保证其数据的局部性和通信的交互，此时平台的物理机的任务位置均可以作为虚拟机开启的
的候选位置。而对于存在关联关系的任务DAG任务，和通信关联的任务则需要在调度的时候解析出这种关联关系。
在虚拟机调度的时候考虑数据的局部性。

对于DAG任务，优于任务之间存在比较强的耦合关系，在资源分配的过程中，可以将前置任务资源分配的结果保留作为后置资源分配的结果。
而前置资源的分配结果，可以取所有后置资源中最大的资源需求。在实际的云计算平台中，进行这么处理的将带来实际的两个优势：
\begin{enumerate}
\item 首先，如果将前置的资源分配的结果直接分配给后置的任务，那么这两个任务的资源只有一份实际的资源被分配。
提高了平台资源的利用情况。
\item 其次，由于对于任务而言，前置任务和后置任务同一个虚拟机或是计算节点中。将可以极大的减少任务之间中间
结果的传输过程，做到加速任务执行的过程。
\end{enumerate}

对于通信关联的任务。任务之间的通信关系往往是实时的，同步的。因此，无法将前置任务的资源直接分配给后置资源。
对于互相通信关联的任务，调度虚拟机的安放策略时，需要考虑的一个重要问题是保证通信的低时延特性。而通信的任务
往往是多个任务间同时进行通信的，在实际的调度任务计算过程中，需要将所有具有通信关系的任务尽量作为一个整体考虑
调度的结果中，尽量保证调度的虚拟机的安放是在同一物理机，如果不能保证，则应当保证其在同一机架上，其次是同一局域网内。
避免跨网段，跨机房的调度结果。

结合实际的作业中，任务之间的关系往往不是只有简单的DAG任务，通信关联或是无关联任务中的一种。任务的关联
关系往往是复杂的。这种关联关系由于这三种关系的组合，这种负杂的关系模型可以采用图论的模型加以描述和建模解决。
建模的规则如下所示：
\begin{enumerate}
\item 将任务抽象成图像中的点，将任务之间的通信关系抽象成图论中的有向边。
\item 对于无关联的任务，他们在图中则被描述成一个孤立的节点。
\item 对于DAG任务，如果任务B需要等待任务A的结束执行，那么在图中的关系则是一条从A指向B的有向边。
\item 对于互相关联的通信任务A和任务B，他们在图中的关系就是两条有向边加以描述，分别是A指向B的有向边和B指向A的有向边。
\end{enumerate}
下图展示了一个计算任务类型的解析图
\begin{figure}[htbp]
\centering\includegraphics[scale=1]{TaskGraph-crop}
\caption{计算任务的解析图}\label{fig:CBTaskGraph}
\end{figure}
将任务的运行和关联关系抽象完毕，借助图论的相关知识，同时结合资源调度分配的原则，我们进行任务
的分配时应当遵守以下规则：
\begin{enumerate}
\item 对于无关联的任务，可以作为一个对立的单元进行分配资源。
\item 对于DAG任务，应该将同一个DAG链上，以DAG链作为分配资源单元进行分配。
\item 对于互相关联的通信任务，在图论中对应的模型是图的联通分量。分配资源时，应当结合联通分量的子集，确保通信的代价不会成为系统
的瓶颈。
\end{enumerate}

对于任务的解析，必须按照上述的建模法则，分配法则进行处理，结合图论算法。我们应当按照下面的流程进行任务的解析过程。
\begin{enumerate}
\item 提取任务间的关联关系，将任务的关联关系描述成一个图的结构。
\item 按照图论的关系，计算强联通分量，标记各个任务属于哪个联通分量。
\item 将在各个联通分量提取出来，其分配序列按照资源请求数目由小到大进行排序。同时将得到的强联通分量看作一个整体的任务。
并将图的模型，结合原有的关系，得到一个新的任务关联关系。这是的任务关系是一个DAG任务图。
\item 将DAG任务图进行拓扑排序，得到新图的一个拓扑序列，在拓扑序列的每个结果中，
如果存在有联通分量缩点造成的新点，该点已步骤3得到的序列替换。
\end{enumerate}
其算法的伪代码算法6所示。
\begin{algorithm} 
\caption {任务关联关系解析} 
\begin{codebox}
\Procname{$\proc{taskCorrlationCalc }(taskData)$}
\li	$taskGraph \leftarrow \proc{buildGraph}(taskData)$ \RComment 初始化任务关系图
\li	\For $each \ point \ v \ in \ taskGraph$    
\li	\Do	
		\proc{tarjan}(v)				
	\End
\li	$newGraph \leftarrow Empty$
\li	\For $each \ scc \ s \ in \ TaskGraph$
\li	\Do
		\proc{makeNewPont}(s, newGraph)
	\End
\li	$seq \leftarrow \proc{topsort}(NewGraph)$
\li	\For $each \ DAG \ chain \ c \ in \ NewGraph$
\li	\Do	
		\proc{markSeq}(c, seq)
	\End 
\li	\Return seq
\end{codebox}
\end{algorithm} 

\subsection{基于DRF算法的分配}
基于主资源分配的算法在前面已经介绍，在先前的主资源分配的算法均是将整个云计算的平台的资源抽象为资源
池，分配资源的公平性的出发点是任务之间的平衡，也就是说，分配资源的时候主要考虑因素的是任务的资源平衡，
而对于系统的负载的均衡主要是基于单资源，经典的例子便是Openstack的filter\_scheduler。基于单资源考虑的因素
往往会造成其他资源的负载过重。

另外，DRF降调一次尽可能分配所有资源，以Mesos为例，其资源的分配是全或无的分配，既在资源分配的过程中，目前的资源尽可能的全部分配出去。
而非以增量的形式进行分配。这会导致一个问题，如果资源被长时间的批处理或是离线的作业的框架占用。即便此时
长时间的批处理的作业的资源利用率很低，但是如果该资源不被框架释放，将导致优先级比较高的在线任务的计算资源
不足，影响平台处理能力。所以一次将所有剩余资源分配不是一个良好的调度决策。

所以在CBDRF中，结合上述观点考虑。我们的资源分配模型做出以下的更改。
\begin{enumerate}
\item	更改资源映射方向，在以往的资源调度中，总是将平台的资源抽象成资源池，而将用户的请求向量作为容器进行分配。
在CBDRF中。这种映射的方向时将用户的请求的抽象成资源池，将平台上的物理机的剩余资源作为分配的容器。既现在的分配
时物理机请求分配任务的资源在该虚拟机上。
\item	由于用户的作业的资源请求时包含多个子任务的资源请求，所以对于资源调度不能是线性的求和抽象成请求池的过程。仍应将
用户的请求作为单个整体进行分配。
\item 对于用户的任务的请求，为了保障多资源分配的公平性，保留计算改任务的domainantShare和DomainantDesire的计算。
\item 对于物理机的请求分配向量，为了保证多资源分配的负载的均衡性，添加计算物理机请求分配向量的domainantShare和DomainDesire的计算。
\end{enumerate}

结合具体的计算的过程修改后的CBDRF的计算的流程如下所示：
\begin{enumerate}
\item 计算所有任务请求的domainantShare和DomainantDesire，并按照其大小进行排序。	

\item	计算所有主机的domainantShare和DomainantDesire的向量。
\item 选取其中首个任务，选择可以分配的主机的domainantShare和domaniantDesrire最小的主机。
\item 如果成功分配，更新所有主机的domainantShare和DomainantDesire的向量。
\item 如果有剩余主机还未分配，继续上述步骤3.
\end{enumerate}

结合上述流程，我们的可以得到CBDRF的分配的主要过程的伪代码：
\begin{algorithm} 
\caption {CBDRF分配过程} 
\begin{codebox}
\Procname{$\proc{CBDFAllocation }()$}
\li	$taskGraph \leftarrow \proc{buildGraph}(taskData)$ \RComment 初始化任务关系图
\li	\For $each \ point \ v \ in \ taskGraph$    
\li	\Do	
		\proc{tarjan}(v)				
	\End
\li	$newGraph \leftarrow Empty$
\li	\For $each \ scc \ s \ in \ TaskGraph$
\li	\Do
		\proc{makeNewPont}(s, newGraph)
	\End
\li	$seq \leftarrow \proc{topsort}(NewGraph)$
\li	\For $each \ DAG \ chain \ c \ in \ NewGraph$
\li	\Do	
		\proc{markSeq}(c, seq)
	\End 
\li	\Return seq
\end{codebox}
\end{algorithm} 
\subsection{关联任务的合并}
在协同计算的平台的环境下，任务的资源请求的合并的出发点是基于关联关系的解析的序列中，对于前置任务A和后置任务B
的合并。对于关联的任务，按照前置任务和后置任务的类型，可以有以下几种情况：

前置任务和后置任务是通信关联关系，那么这两个任务对资源的请求的合并时两个任务资源请求的均必须得到满足。所以中情况
下的资源的合并时2个任务资源请求的线性叠加。
\begin{figure}[htbp]
\centering\includegraphics[width=0.8\textwidth]{MergeCase3-crop}
\caption{通信关任务的合并}\label{fig:MergeCase3}
\end{figure}

前置任务和后置任务是DAG关联关系，那么这个两个任务的资源请求时DAG关系。
如果这两个任务不是被合并的历史。那么比较前置任务和后置任务的大小情况，保留较大的。
\begin{figure}[htbp]
\centering\includegraphics[width=0.88\textwidth]{MergeCase2-1-crop}
\caption{DAG任务的情形1合并}\label{fig:MergeCase2-1}
\end{figure}

若果前置任务和后置任务中存在一个时已经被合并的任务，那么按照以下的规则进行合并。本文以后置为合并的为例，
此时前置任务的资源请求可以作为后置任务资源请求
的一个可能候选项。因此，在合并的时候，需要遍历后置任务合并的请求的历史，考察后置任务合并的历史。如果后置历史任务的
资源需求中存在各项资源需求均小于前置资源请求的任务请求序列。那么在后置的历史中忽略其中的后置的一项资源请求。合并的结果
结果为后置任务的请求向量与忽略的资源向量的差值雨前置资源需求的和。
\begin{figure}[htbp]
\centering\includegraphics[width=0.8\textwidth]{MergeCase2-2-crop}
\caption{DAG任务的情形2合并}\label{fig:MergeCase2-2}
\end{figure}

相反的如果前置资源存在小于后置资源的某一项任务时，忽略
此前置的任务的资源需求。
\begin{figure}[htbp]
\centering\includegraphics[width=0.8\textwidth]{MergeCase2-3-crop}
\caption{DAG任务的情形3合并}\label{fig:MergeCase2-3}
\end{figure}

如果不是上述的两种情况，则按照2个通信关联任务进行合并。
\begin{figure}[htbp]
\centering\includegraphics[width=0.8\textwidth]{MergeCase2-4-crop}
\caption{DAG任务的情形4合并}\label{fig:MergeCase2-4}
\end{figure}

前置任务和后置任务的关系时无关联关系。那么此时采取基于通信关联任务进行合并。
\begin{figure}[htbp]
\centering\includegraphics[width=0.8\textwidth]{MergeCase1-crop}
\caption{无关联关系任务的合并}\label{fig:MergeCase1}
\end{figure}

由于合并DAG作业必须在有向无环图上进行。所以合并的顺序十分重要，CBDRF的合并顺序和合并法则按照如下的情况进行处理：
首先如果存在强联通分量的任务还没有合并结束，选取一个强联通分量的通信关联任务的合并，此时按照哈夫曼编码的原则，每次选取最小的两个请求进行合并。
如果不存在强联通分量的关联任务，那么进行DAG关联的合并，此时由于图已经是有向无环图，所以合并时每次选取资源需求最小的前置任务和后置任务进行合并。
如果DAG任务合并完毕，各个无关联的任务的合并时按照哈夫曼合并法则合并即可。

\section{CBDRF调度系统的组成}
在大规模的云计算平台下，云计算的资源调度在是云计算的平台的核心模块，本章从关联任务的角度出发。设计了一个基于关联任务
的中心调度器，设计并实现了基于关联关系的主资源调度算法。在该算法的基础之上，进一步的实现了基于关联关系的主资源调度器。
该调度器主要包含以下三个子模块，资源管理控制器，任务调度解析起喝资源调度迭代控制器。
\begin{figure}[htbp]
\centering\includegraphics[width=0.8\textwidth]{CBDRFDesign-crop}
\caption{CBDRF调度系统的组成}\label{fig:CBDRFDesign}
\end{figure}
\subsection{资源管理控制器}
在云计算平台中，资源调度管理器是资源调度器的一个必不可少的组件。资源调度管理器一般用于接受资源调度监控系统所获取的物理
宿主机的资源情况。同时维护和更新资源状态信息，保证资源状态信息的一致性。进一步，资源调度管理器除了完成与平台监控系统的
交互之外，在CBDRF中需要对资源监控所采取的数据进行预处理。从监控的数据中抽取调度算法所需要的数据，同时按照调度系统的需要
需要预先计算处理额外的请求已减少调度迭代器的计算，从而获得更好的计算性能。另外，由于云计算的平台存在实时并发的作业，资源
管理器必须作为一个长期服务的进程存在，能够实时获取整个平台的状态，为调度迭代器控制获得准确的数据。在此基础之上，还应当保证
并发控制的原子性和事务性。

综上所述，在CBDRF系统中资源管理器涉及的操作主要有以下：
\begin{enumerate}
\item 与资源监控接口对接，实时获取云计算集群资源状态情况。
\item 结合调度迭代控制器，从监控数据中抽取平台中各个物理机的资源情况，包括CPU，内存，带宽，硬盘的相应状态。
\item 根据云计算集群中每个物理机的资源情况，在调度迭代器控制器请求时，实时的计算出集群中的资源总量和剩余资源总量，
在CBDRF调度中，资源管理器还应当计算当前状态下各个物理机的dominantShare和doaminDesire。
\item 保证数据的一致性，保证集群状态信息的一致性，在并发环境下。在调度器迭代器高并发作业的情况下，提供对资源
的一致性，原子性和事务性。
\end{enumerate}

\subsection{任务调度解析器}
在面向计算任务的协同计算平台的背景下，单个任务往往不是只有一个单一的作业完成的。往往一个作业（Job）会有许多的任务（task）组成。
而不同的计算框架的task见的关系一般是不同的。MPI的计算任务往往是双向关联的通信关心任务，而Hadoop的任务大多以Map－Reduce等
DAG作业为主。而任务调度解析器必须能够解析不同框架提出的资源请求。

在CBDRF的调度系统中，任务解析器主要是重要的前端预处理流程和资源请求封装进行封装。由于调度迭代控制器需要对资源请求
进行相应的操作，任务调度解析器需要对不同框架的任务的资源请求进行操作，这就要求任务调度解析器必须封装资源请求的操作。
另外，对于关联任务的解析，任务调度解析器负责处理关联任务之间的解析，需要针对无关联任务，DAG任务，和通信任务设计相应
的算法进行解析，将最终的解析的结果以带有特殊标记的序列的形式提交给调度迭代控制器。具体来说，目前CBDRF调度系统主要
运行一下的功能。
\begin{enumerate}
\item 接受框架发来的任务调度请求用户的请求json文件，提取调度迭代器关心的CPU，内存等资源请求，同时进一步封装用户的资源请求。
\item 解析框架任务关联请求，运行强联通分量，拓扑排序等图论算法，产生带有特殊标记的任务序列。
\item 提供合并操作的封装操作，在利用并查集的操作上，提供后续的资源调度迭代器进行操作用以进行合并操作，
进一步资源调度迭代器能够查询合并历史产生资源调度结果。
\end{enumerate}

\subsection{调度迭代器}
调度迭代器是CBDRF调度系统的核心模块。资源调度迭代器主要进行调度的迭代控制过程，产生资源调度结果。
调度迭代器进一步包括资源调度迭代控制器，资源调度迭代合并器，资源调度迭代排序器，资源调度迭代评估器。
四个模块。

$\bullet$ 调度迭代控制器

资源调度迭代控制器是资源调度迭代器的重要控制元件，主要进行调度的迭代控制，是执行调度算法的重要工作
模块。其控调度度迭代合并器，资源调度调度迭代合并器以及资源调度排序器协同工作，判断迭代终止条件。
并且资源调度迭代控制器在迭代的迭代计算过程中，需要对资源请求进行分配，进行实际的分配的资源的计算。
资源调度迭代控制器涉及的主要操作有以下几个：
\begin{enumerate}
\item 接收资源请求解析器的请求，控制资源调度迭代器的初始化工作
\item 控制资源调度迭代排序器，根据dominantShare和dominantDesire进行物理机的评估排序。
\item 资源调度迭代器进行调度控制，根据贪心算法，采取调度控制过程，采用max－min方法，对dominantShare进行贪心分配。
\item 调用资源调度迭代合并器，控制解析出的同一连通分量的请求的进行合并，
\item 控制调度迭代器的调度迭代次数，并判断合并的结果是否能够进行下一轮迭代。
\item 迭代终止时，返回最终的调度结果。
\end{enumerate}
\begin{figure}[htbp]
\centering\includegraphics[scale=0.618]{CBDRFIter-crop}
\caption{调度迭代器的迭代流程}\label{fig:CBDRFIter}
\end{figure}


$\bullet$ 调度迭代合并器

调度迭代合并器的合并操作是调度迭代操作中的重要环节。用以产生中间迭代的调度中间结果。实际在调度的过程中，
调度迭代合并器负责按照CBDRF算法的设计进行合并请求的操作，按照CBDRF设计的算法，采用并查集的方法，根据
任务解析器发送的带有标记的任务序列进行合并操作。

$\bullet$ 调度迭代排序器

调度迭代排序器是调度迭代的操作中的辅助环节。这个排序器的主要作用是辅助调度迭代控制器进行分配的过程中。
为了能够对domainantShare进行贪心分配，必须对物理机和调度器分别排序，按照不同DomainantShare和DomainantDesire
进行排序，为了能够加速这个排序过程，调度迭代排序器对资源的合并操作采用了以堆为主要数据结构进行排序。
因为每次的迭代过程中，对物理机的操作的排序均是以原始状态进行，所以在排序器的维护中，保留了原始物理机上
资源信息状态的已排序副本，用以加速整个调度的进行。

$\bullet$  调度迭代评估器
调度迭代评估器是调度迭代器的最后一个环节，也是资源调度迭大器的一个重要模块。这个模块用以评估调度结果的公平性，
负载均衡性，等因素。支持多个评估函数的添加。在本此调度实现上，采用了基于简氏系数的公平评价指数。另外，
资源调度迭代评估器除了对调度结果的进行评，记录当前的评估结果之外，资源调度迭代评估器的
另一个重要作用同是与先前已经计算的迭代产生的调度中间结果进行比较，如果当前的评估值优于先前的
调度结果则记录调度结果为当前结果，否则，舍弃当前的结果，通知调度迭代控制器进行下一轮迭代器。

\section{CBDRF调度系统的实现}
本节结合CBDRF的调度系统的关键算法以及CBDRF调度系统的系统设计，给出了其调度系统的一种实现方式。
\subsection{资源管理控制器的实现}
资源管理控制器为每个物理机创建host实例，每个实例为四元组（cpuTotal,cpuUsed, memTotal, memUsed）其中：
\begin{itemize}
\item cpu表示分别单个物理机表示cpu核数。
\item cpuUsed表示单个物理机已经使用的cpu核数。
\item memTotal表示单个物理机内存总数，以GB为单位。
\item memUesd表示单个物理已经使用内存总数，以GB为单位。
\end{itemize}

上述数值均通过云计算平台的监控接口获取这些数值。另外，资源管理控制器还要计算平台的dominantShare以及dominantDesire，并按照dominantShare的大小由小到大的排序资源向量其计算向量有

所有剩余资源总量
\begin{equation}
R=\left({r}_{1},…,{r}_{m}\right)
\end{equation}

单个物理机i资源总量的向量表示如下所示：
\begin{equation}
{HT}_{i}=\left({ht}_{i,1},…{ht}_{i,m} \right)
\end{equation}

单个物理机i已分配资源总量：
\begin{equation}
{HU}_{i}=\left({hu}_{i,1},…{hu}_{i,m}\right)
\end{equation}

单个物理机i的dominantShare计算方法：
\begin{equation}
{HS}_{i} = \max \limits_{1 \leq j \leq m} {hu}_{i,j}/{{r}_{j}} 
\end{equation}

单个物理机i的dominantDesire计算方法:
\begin{equation}
{HD}_{i}=\max \limits_{1 \leq j \leq m } {ht}_{i,j}-{hu}_{i,j} 
\end{equation}

相同的dominantShare则按照doaminantDesire的大小由小到大进行排序。
\subsection{任务解析器的实现}
\begin{enumerate}
\item 首先，资源解析器解析用户请求，为每个请求初始化request实例，每个实例为五元组（cpu，mem，relatedRequest ,mergeHistory, scheduledHost）其中：
CPU表示任务请求的虚拟机的CPU核数。
mem表示任务请求的虚拟机内存大小，以GB为单位。
relatedRequest表示关联任务请求集合.
mergeHistory表示合并历史，调度迭代器结合scheduledHost从合并历史中解析最终的调度结果。
scheduledHost表示请求的调度结果，通过mergeHistory解析最终请求的调度结果。
上述CPU，mem，relatedRequest的初始值从用户的请求中获取，mergeHistory和scheduledHost初始集均为空集。

\item 由于关联任务之间互相存在网络通信，在同一个物理机上放置两台存在网络通信的虚拟机可以提升系统性能，
并且可以提升资源的利用效率，因此将互相有交流的任务抽象成点，将他们之间网络通信关系抽象成边，
通过relatedRequest将请求解析抽象成一个关系图。由资源解析器运行关联任务解析算法计算任务关系图的强联通分量。
标记在request实例中。
\end{enumerate}


\subsection{调度迭代器的实现}
\begin{enumerate}
\item request实例向资源调度迭代器发送解析数据，同时资源调度迭代器向资源管理控制器发送请求，以获取云计算平台的的实时资源状态。
将用户的请求作为要分配的资源池，当多个任务资源请求到来的时候将这些资源请求抽象为分配给物理机的总资源。
其中任务请求向量所拥有的资源的占有率中的最大值称任务的dominantShare.同时计算dominantDesire为资源向量上剩余最多的资源。其计算方式如下所示：

作业请求的i总请求资源总量：
\begin{equation}
{TR}_{i}=\left({tr}_{i,1},…{tr}_{i,m}\right)
\end{equation}

任务请求i的dominantShare计算方法：
\begin{equation}
{TS}_{i}=\max \limits_{1 \leq j \leq m} {{tr}_{i,j}}/{{t}_{j}}
\end{equation}

任务请求i的dominantDesire计算方法
\begin{equation}
{TD}_{i}=\max \limits_{1 \leq j \leq m} {tr}_{i,j}
\end{equation}

作业请求资源总数向量：
\begin{equation}
T=\left({t}_{1},…{t}_{m}\right)
\end{equation}
\item 由资源调度迭代排序器和资源调度迭代器运算贪心算法，进行基于DRF算法的分配操作。：
\item 资源调度迭代评估器利用Jain’s fairness index:简氏公平指数，计算资源请求request的dominantShare向量
$TS\left({ts}_{1},{ts}_{2},…{ts}_{k}\right )$，云计算平台物理机向量dominantShare向量$HS\left({hs}_{1},{hs}_{2},…{hs}_{n}\right )$，记录此时的$Value = \frac{J(TS)}{J(HS)}$和分配方案。其中简氏公平指数的计算方法如下所述：
\item 资源调度迭代评估器计算$Value = \frac{J(TS)}{J(HS)}$，如果大于之前的最优值，记录此式的解决方案。
\item 资源调度迭代合并器从已经计算的任务强连通分量重中选取排序好的request中按照哈夫曼合并法则，选取最小的2个request进行请求合并，如果此时的任务关系图成为一个有向无环图，
则在此有向无环图上进行拓扑排序，选取拓扑排序节点上相邻最小的request进行合并，从而更新合并mergeHistory跳至步骤3，否则跳至步骤6.
\item 算法结束，输出解决方案。
\end{enumerate}

\section{本章小结}
本章详细的介绍了CBDRF调度系统和调度算法的设计，实现的过程，给出了调度算法设计的关键算法和核心模块的设计。