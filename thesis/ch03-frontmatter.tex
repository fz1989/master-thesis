%% ----------------------------------------------------------------------
%% START OF FILE
%% ----------------------------------------------------------------------
%% 
%% Filename: ch03-frontmatter.tex
%% Author: Fred Qi
%% Created: 2012-12-26 09:12:47(+0800)
%% 
%% ----------------------------------------------------------------------
%%% CHANGE LOG
%% ----------------------------------------------------------------------
%% Last-Updated: 2013-03-12 08:16:15(+0800) [by Fred Qi]
%%     Update #: 19
%% ----------------------------------------------------------------------
\chapter{CBDRF算法的相关技术}
\label{chap:outline}
\section{图的联通性算法}
\subsection{强联通分量}
在有向图G中，如果两个顶点可以相互通达，则称两个顶点强连通(strongly connected)。
如果有向图G的每两个顶点都强连通，称G是一个强连通图。
非强连通图有向图的极大强连通子图，称为强连通分量(strongly connected components)。

下图中，子图{1，2，3}为一个强连通分量，因为顶点1，2，3两两可达。{4}，{5，6}也分别是两个强连通分量。

直接根据定义，用双向遍历取交集的方法求强连通分量，时间复杂度为O(N*N+M)。更好的方法有算法有，Tarjan算法，Kosaraju算法。
其中Tarjan算法和Kosaraju算法均是是基于对图深度优先搜索的算法,与Kosaraju算法不同，
Tarjan算法只进行一遍深度优先搜索索，较Kosaraju算法进行两遍深度优先搜索有30\%的性能提升。

Tarjan算法以一个有向图G作为输入，每个强连通分量为搜索树中的一棵子树
首先定义结点u的深度优先搜索标号DFN(u)，表示节点u是被访问的次序编号。
此外，每个结点u还有一个值Low(u)，表示从u出发经有向边可到达的所有结点中最小的次序号。
显然Low(u)总是不大于DFN(u)，且当从v出发经有向边不能到达其他结点时，这两个值相等，
此时，以u为根的搜索子树上的所有节点属于同一个强连通分量。
其中Low(u)在深度优先搜索的过程中求得，通过上述可以发现以u为根的搜索子树上的所有节点属于同一个
强连通分量当且仅当DFN(u)=Low(u)时。而Low(u)的计算由以下公式给出：
$$Low(u)=\min
\begin{cases}
DFN(u) & \\
Low(v)& \text{(u,v)为树枝边，u为v的父节点}\\
DFN(v)& \text{(u,v)为指向栈中节点的后向边(非横叉边)}
\end{cases}$$

由此可得，Tarjan算法的基本流程如下：
\begin{enumerate}
\item 任选图G中的未被访问的结点u开始进行深度优先搜索遍历，如果深度优先搜索结束后仍有未访问的结点，则再从中任选一点再次进行。
\item 搜索过程中标记已访问的节点，如果是已访问的结点不再访问。
\item 搜索时，把当前搜索树中未处理的节点加入一个堆栈，回溯时可以判断栈顶到栈中的节点是否为一个强连通分量。
\end{enumerate}

由此可以得到Tarjan算法在搜索时的主要的伪代码
\begin{algorithm} 
\caption {Tarjan Algorithm} 
\begin{codebox}
\Procname{$\proc{tarjan}(u)$}
\li	$Index \leftarrow time + 1$
\li	$DFN[u] \leftarrow time$
\li	$Low[u] \leftarrow time$
\li	$Stack.push(u)$
\li	\For $each (u, v)$ $in$ $E[u]$
\li		\Do  \If $\proc{visted}(v)$
\li			\Then
				$\proc{tarjan}(v)$                  
\li            			$Low[u] \leftarrow \min(Low[u], Low[v])$
\li        		 \ElseIf $\proc{inStack}(v)$ 
\li            			\Then $Low[u] \leftarrow \min(Low[u], DFN[v])$
			\End
		\End
\li	\If $DFN[u] \isequal Low[u]$
\li		\Then \While $u != v$
\li				\Do $v \leftarrow$ $\proc{Stack.pop}()$                  
\li            				$\proc{print}(v)$
				\End 
		\End
\end{codebox}
\end{algorithm} 
\subsection{拓扑排序}
在图论中，如果一个有向图无法从某个顶点出发经过若干条边回到该点，则这个图是一个有向无环图（DAG图）。
因为有向图中一个点经过两种路线到达另一个点未必形成环，
因此有向无环图未必能转化成树，但任何有向树均为有向无环图。如右图，不为有向树，但为有向无环图。

对一个有向无环图(Directed Acyclic Graph简称DAG)G进行拓扑排序，是将G中所有顶点排成一个线性序列，
使得图中任意一对顶点u和v，若边(u,v)∈E(G)，则u在线性序列中出现在v之前。
通常，这样的线性序列称为满足拓扑次序(Topological Order)的序列，
简称拓扑序列。简单的说，由某个集合上的一个偏序得到该集合上的一个全序，这个操作称之为拓扑排序。

一个较大的工程往往被划分成许多子工程，我们把这些子工程称作活动(activity)。
在整个工程中，有些子工程(活动)必须在其它有关子工程完成之后才能开始，
也就是说，一个子工程的开始是以它的所有前序子工程的结束为先决条件的，
但有些子工程没有先决条件，可以安排在任何时间开始。
为了形象地反映出整个工程中各个子工程(活动)之间的先后关系，
可用一个有向图来表示，图中的顶点代表活动(子工程)，图中的有向边代表活动的先后关系
，即有向边的起点的活动是终点活动的前序活动，只有当起点活动完成之后，其终点活动才能进行。
通常，我们把这种顶点表示活动、边表示活动间先后关系的有向图称做顶点活动网(Activity On Vertex network)，
简称AOV网。

在AOV网中，若不存在回路，则所有活动可排列成一个线性序列，使得每个活动的所有前驱活动都排在该活动的前面，我们把此序列叫做拓扑序列(Topological order)，由AOV网构造拓扑序列的过程叫做拓扑排序(Topological sort)。AOV网的拓扑序列不是唯一的，满足上述定义的任一线性序列都称作它的拓扑序列。

由AOV网构造拓扑序列的拓扑排序算法主要是循环执行以下两步，直到不存在入度为0的顶点为止。
\begin{algorithm} 
\caption {Topological Sort} 
\begin{codebox}
\Procname{$\proc{TopologicalSort}(G)$}
\li Queue.clear()
\li \For $each$ $vertex $ $u$ $in$ $G$
\li	\Do \If $\attribii{u}{indeg}  \isequal 0$
\li		\Then	$Q.push(u)$	
\li				$isVisited[u] \leftarrow True$
		\End
	\End
\li \While $\attribii{Queue}{\proc{size}()} > 0$
\li	\Do	$u \gets \attribii{Queue}{\proc{front}()}$
\li		$\attribii{Queue}{\proc{pop}()}$
\li		\For $each$ $(u,v)$ $in$ $ Edge[v]$
\li			\Do	$ \attribii{v}{indeg} \leftarrow  \attribii{v}{indeg} - 1$
\li			\If $\attribii{v}{indeg}  \isequal $0 and $isVisited[v] \isequal False$
\li				\Then	$Q.push(v)$
\li						$isVisited[v] \leftarrow True$
				\End
	\End
   \End
\end{codebox}
\end{algorithm} 

\begin{enumerate}
\item 选择一个入度为0的顶点并输出之；
\item 从网中删除此顶点及所有出边。
\item 循环结束后，若输出的顶点数小于网中的顶点数，则输出“有回路”信息，否则输出的顶点序列就是一种拓扑序列。
\end{enumerate}

\subsection{并查集}
在计算机科学中，并查集是一种树型的数据结构，其保持着用于处理一些不相交集合（Disjoint Sets）的合并及查询问题。有一个联合-查找算法（union-find algorithm）定义了两个操作用于此数据结构：

\begin{itemize}
\item Find：确定元素属于哪一个子集。它可以被用来确定两个元素是否属于同一子集。
\item Union：将两个子集合并成同一个集合。
\end{itemize}

因为它支持这两种操作，一个不相交集也常被称为联合-查找数据结构（union-find data structure）或合并-查找集合（merge-find set）。
其他的重要方法，MakeSet，用于建立单元素集合。有了这些方法，许多经典的划分问题可以被解决。

为了更加精确的定义这些方法，需要定义如何表示集合。一种常用的策略是为每个集合选定一个固定的元素，称为代表，以表示整个集合。接着。Find(x)返回x所属集合的代表，而Union使用两个集合的代表作为参数。


并查集实现方式有多种，包括并查集链表和并查集森林，其中并查集森林是并查集的高效实现。并查集森林是一种将每一个集合以树表示的数据结构，其中每一个节点保存着到它的父节点的引用。这个数据结构最早由Bernard A. Galler和Michael J. Fischer于1964年提出，但是经过了数年才完成了精确的分析。

在并查集森林中，每个集合的代表即是集合的根节点。“查找”根据其父节点的引用向根行进直到到底树根。“联合”将两棵树合并到一起，这通过将一棵树的根连接到另一棵树的根。实现这样操作的一种方法是：

这是并查集森林的最基础的表示方法，这个方法不会比链表法好，这是因为创建的树可能会严重不平衡；然而，可以用两种办法优化。

第一种优化方式是按秩合并，即总是将更小的树连接至更大的树上。因为影响运行时间的是树的深度，
更小的树添加到更深的树的根上将不会增加秩除非它们的秩相同。在这个算法中，术语“秩
”替代了“深度”，因为同时应用了路径压缩时（见下文）秩将不会与高度相同。
单元素的树的秩定义为0，当两棵秩同为r的树联合时，它们的秩r+1。
只使用这个方法将使最坏的运行时间提高至每个MakeSet、
Union或Find操作O($\log n$)。采用按秩合并的Union伪代码如下所示：
\begin{algorithm} 
	\caption {Union-Set Union} 
	\begin{codebox}
		\Procname{$\proc{Union}(u,v)$}
\li			$rootu = \proc{Find}(u)$
\li			$rootv = \proc{Find}(v)$
\li			\If	$rootu$ $!=$ $rootv$
\li				\Then
					\If $\attribii{u}{rank} < \attribii{v}{rank}$
\li						\Then
							$\attribii{u}{parent} \leftarrow \attribii{v}{parent}$
\li							$\attribii{v}{rank} \leftarrow \attribii{v}{rank} + \attribii{u}{rank}$
\li						\Else
\li							$\attribii{v}{parent} \leftarrow \attribii{u}{parent}$
\li							$\attribii{u}{rank} \leftarrow  \attribii{v}{rank} + \attribii{u}{rank}$
						\End
				\End
\li			\Return	$\attribii{u}{parent}$
	\end{codebox}
\end{algorithm} 

另外一种优化的方式是采用路径压缩，这是一种在执行“查找”时扁平化树结构的方法。
关键在于在路径上的每个节点都可以直接连接到根上；
他们都有同样的表示方法。
为了达到这样的效果，Find递归地经过树，
改变每一个节点的引用到根节点。
得到的树将更加扁平，
为以后直接或者间接引用节点的操作加速。
采用路径压缩的Find伪代码如下所示：
\begin{algorithm} 
	\caption {Union-Set Find} 
	\begin{codebox}
		\Procname{$\proc{Find}(u)$}
\li			\If $\attribii{u}{parent}$ $!=$ $root$
\li			\Then	$\attribii{u}{parent} \leftarrow \proc{Find}(\attribii{u}{parent})$ \End
\li			\Return	$\attribii{u}{parent}$
	\end{codebox}
\end{algorithm} 

这两种技术可以互补，可以应用到另一个上，每个操作的平均时间仅为O($\alpha(n)$)，$\alpha(n)$是n = f(x) = A(x,x)的反函数，并且A是急速增加的阿克曼函数。因为$\alpha$(n)是其的反函数，$\alpha$(n)对于可观的巨大n还是小于5。因此，平均运行时间是一个极小的常数。

\section{公平性的度量}
\subsection{max-min公平}
\subsection{简氏公平}
\section{本章小结}
%% ----------------------------------------------------------------------
%%% END OF FILE 
%% ----------------------------------------------------------------------
